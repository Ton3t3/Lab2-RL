{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20ba7a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright [2025] [KTH Royal Institute of Technology] \n",
    "# Licensed under the Educational Community License, Version 2.0 (ECL-2.0)\n",
    "# This file is part of the Computer Lab 2 for EL2805 - Reinforcement Learning.\n",
    "\n",
    "\n",
    "# Load packages\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import warnings, sys\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def running_average(x, N):\n",
    "    ''' Function used to compute the running average\n",
    "        of the last N elements of a vector x\n",
    "    '''\n",
    "    if len(x) >= N:\n",
    "        y = np.copy(x)\n",
    "        y[N-1:] = np.convolve(x, np.ones((N, )) / N, mode='valid')\n",
    "    else:\n",
    "        y = np.zeros_like(x)\n",
    "    return y\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    model = torch.load('neural-network-1.pth')\n",
    "    print('Network model: {}'.format(model))\n",
    "except:\n",
    "    print('File neural-network-1.pth not found!')\n",
    "    sys.exit(-1)\n",
    "\n",
    "# Import and initialize Mountain Car Environment\n",
    "env = gym.make('LunarLander-v3')\n",
    "# If you want to render the environment while training run instead:\n",
    "# env = gym.make('LunarLander-v3', render_mode = \"human\")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "# Parameters\n",
    "N_EPISODES = 50            # Number of episodes to run for trainings\n",
    "CONFIDENCE_PASS = 50\n",
    "\n",
    "# Reward\n",
    "episode_reward_list = []  # Used to store episodes reward\n",
    "\n",
    "# Simulate episodes\n",
    "print('Checking solution...')\n",
    "EPISODES = trange(N_EPISODES, desc='Episode: ', leave=True)\n",
    "for i in EPISODES:\n",
    "    EPISODES.set_description(\"Episode {}\".format(i))\n",
    "    # Reset enviroment data\n",
    "    done, truncated = False, False\n",
    "    state = env.reset()[0]\n",
    "    total_episode_reward = 0.\n",
    "    while not (done or truncated):\n",
    "        # Get next state and reward.  The done variable\n",
    "        # will be True if you reached the goal position,\n",
    "        # False otherwise\n",
    "        q_values = model(torch.tensor(state))\n",
    "        _, action = torch.max(q_values, dim=0)\n",
    "        next_state, reward, done, truncated, _ = env.step(action.item())\n",
    "\n",
    "        # Update episode reward\n",
    "        total_episode_reward += reward\n",
    "\n",
    "        # Update state for next iteration\n",
    "        state = next_state\n",
    "\n",
    "    # Append episode reward\n",
    "    episode_reward_list.append(total_episode_reward)\n",
    "\n",
    "\n",
    "# Close environment \n",
    "env.close()\n",
    "\n",
    "\n",
    "avg_reward = np.mean(episode_reward_list)\n",
    "confidence = np.std(episode_reward_list) * 1.96 / np.sqrt(N_EPISODES)\n",
    "\n",
    "\n",
    "print('Policy achieves an average total reward of {:.1f} +/- {:.1f} with confidence 95%.'.format(\n",
    "                avg_reward,\n",
    "                confidence))\n",
    "\n",
    "if avg_reward - confidence >= CONFIDENCE_PASS:\n",
    "    print('Your policy passed the test!')\n",
    "else:\n",
    "    print(\"Your policy did not pass the test! The average reward of your policy needs to be greater than {} with 95% confidence\".format(CONFIDENCE_PASS))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
